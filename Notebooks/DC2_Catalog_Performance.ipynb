{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tests of Coadd Catalog Access\n",
    "\n",
    "Test the performance of data manipulations of the static coadd catalogs.\n",
    "\n",
    "1. Identify trivial, moderate, and worst-case use case examples.\n",
    "2. Measure performance on\n",
    "    a. single patch\n",
    "    b. a single tract\n",
    "    c. the full dataset\n",
    "    3. Record data sizes of each of the above a, b, c.\n",
    "4. Determine if performance considerations mean we should generate a static file that contains a restricted set in columns.\n",
    "5. Look into again using full tables functionality to write HDF5 files so that they can be read by column efficiently. This was previously not possible because of an error trying to write the thousands of columns in our full coadd catalogs. This is #158\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the GCR reader outside of NERSC environment.\n",
    "Want to use on specification of YAML file that lives here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config_files = ('dc2_coadd_run1.1p_serenity', 'dc2_coadd_run1.1p_tract4850_serenity')\n",
    "for name in custom_config_files:\n",
    "    custom_config_file = '%s.yaml' % name\n",
    "    config = GCRCatalogs.register.load_yaml(custom_config_file)\n",
    "    GCRCatalogs.available_catalogs[name] = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529 ms ± 4.88 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850_serenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_onetract = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850_serenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.18 s ± 71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_serenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_serenity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the GCR Catalog is, in principle, just the initialization of the catalog.  In practice the GCRCatalog reader does need to read through all of the metadata in the HDF5 files to figure out what's in there and available.  The onetract version is reading a 7.4 GB file that should fit in memory.  The full Run 1.1p is 78 GB, which does not fit in the average desktop memory.  This size could pontentially fit in the memory of various high-memory shared nodes.  This difference in size is conveniently roughly a factor of 10.  We should expect \n",
    "\n",
    "We can control the memory caching within GCR to clear the cache to reset for performance tests.  It's harder to control the underlying caching of the GPFS and kernel filesystem memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_slow(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog'.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    average_gmr = np.mean(catalog['mag_g'] - catalog['mag_r'])\n",
    "    return average_gmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_faster(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog'.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    mag_g, mag_r = catalog.get_quantities(['mag_g', 'mag_r'])\n",
    "    average_gmr = np.mean(catalog['mag_g'] - catalog['mag_r'])\n",
    "    return average_gmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_stellar_locus():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.3 ms ± 504 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_slow(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 182.96 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.9 s ± 23.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_slow(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 182.96 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.9 s ± 23.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 182.96 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.9 s ± 23.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6892380"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gc['mag_g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to using Pandas to read the data files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "tract = 4850\n",
    "datafile_basename = 'merged_tract_%d.hdf5' % tract\n",
    "datafile = os.path.join(gc.base_dir, datafile_basename)\n",
    "\n",
    "key_prefix = 'coadd'\n",
    "nx, ny = 8, 8\n",
    "patches = ['%d%d' % (i, j) for i in range(nx) for j in range (ny)]  # Note '%d%d' instead of '%d,%d'\n",
    "patch = patches[0]\n",
    "key = '%s_%d_%s' % (key_prefix, tract, patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.1 ms ± 764 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = pd.read_hdf(datafile, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tract_into_pandas(tract, key_prefix='coadd'):\n",
    "    nx, ny = 8, 8\n",
    "    patches = ['%d%d' % (i, j) for i in range(nx) for j in range (ny)]  # Note '%d%d' instead of '%d,%d'\n",
    "\n",
    "    dfs = []\n",
    "    for patch in patches:\n",
    "        key = '%s_%d_%s' % (key_prefix, tract, patch)\n",
    "        try:\n",
    "            df = pd.read_hdf(datafile, key=key)\n",
    "        except:\n",
    "            continue\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.3 s ± 1.06 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = load_tract_into_pandas(tract=tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_tract_into_pandas(tract=tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
